{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Try DualDn with ANY in-the-wild noisy raw images.\n",
        "\n",
        "This notebook shows a minimal inference pipeline for **DualDn**, letting you denoise **ANY** noisy RAW images from **ANY** camera or smartphone.\n",
        "\n",
        "\n",
        "**You ONLY needs to prepare 3 things:**\n",
        "\n",
        "\n",
        "1.   Prepare Your Data or Our [In-the-wild Dataset](https://mycuhk-my.sharepoint.com/my?id=%2Fpersonal%2F1155231343%5Flink%5Fcuhk%5Fedu%5Fhk%2FDocuments%2FDualDn%2FDatasets%2Freal%5Fcapture%2Ezip&parent=%2Fpersonal%2F1155231343%5Flink%5Fcuhk%5Fedu%5Fhk%2FDocuments%2FDualDn%2FDatasets&ga=1)\n",
        "\n",
        "  *   Noisy RAW files (e.g. .dng, .arw, etc.)\n",
        "  *   Corresponding sRGB exports from your phone's [Pro/Manual mode](https://consumer-tkb.huawei.com/weknow/applet/simulator/en-gb00739859/procamera.html).\n",
        "\n",
        "      (*P.s. raw images are used for DualDn's input, and the corresponding sRGB image are used for ISP simulation during inference since DualDn only trained with our differentiable ISP.*)\n",
        "\n",
        "\n",
        "\n",
        "2.   Get the Pretrained Model\n",
        "\n",
        "  Download our [pretrained model](https://mycuhk-my.sharepoint.com/my?id=%2Fpersonal%2F1155231343%5Flink%5Fcuhk%5Fedu%5Fhk%2FDocuments%2FDualDn%2FPretrained%5Fmodel%2FDualDn%5FBig%2Epth&parent=%2Fpersonal%2F1155231343%5Flink%5Fcuhk%5Fedu%5Fhk%2FDocuments%2FDualDn%2FPretrained%5Fmodel&ga=1) into your local desktop.\n",
        "\n",
        "\n",
        "3.   Change the Google Colab's runtime type to a GPU-based one.\n",
        "\n"
      ],
      "metadata": {
        "id": "XYeJOi9UdDVH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Prepare the code and environment."
      ],
      "metadata": {
        "id": "sYVrJ6CFfARf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A00dr-dmcNhG"
      },
      "outputs": [],
      "source": [
        "# Clone the DualDn repo\n",
        "!git clone https://github.com/OpenImagingLab/DualDn.git\n",
        "\n",
        "# Cd the path\n",
        "%cd DualDn\n",
        "\n",
        "# Install the dependency\n",
        "!pip install -r docs\colab_requirements.txt\n",
        "\n",
        "# Install the EXIF tool to process raw data\n",
        "!apt-get update -qq\n",
        "!apt-get install -y libimage-exiftool-perl\n",
        "!exiftool -ver"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Upload images and our pre-trained model.\n",
        "\n",
        "*   Use [our in-the-wild testset](https://mycuhk-my.sharepoint.com/my?id=%2Fpersonal%2F1155231343%5Flink%5Fcuhk%5Fedu%5Fhk%2FDocuments%2FDualDn%2FDatasets%2Freal%5Fcapture%2Ezip&parent=%2Fpersonal%2F1155231343%5Flink%5Fcuhk%5Fedu%5Fhk%2FDocuments%2FDualDn%2FDatasets&ga=1) or your own data.\n",
        "\n",
        "*   Rename the images to the same prefix:\n",
        "\n",
        "  E.g.  \n",
        "  Raw: *Xiaomi_0001.dng*  \n",
        "  sRGB: *Xiaomi_0001.jpg*\n",
        "  \n",
        "*   Put them in /content/DualDn/datasets/real_capture, following:\n",
        "      ```\n",
        "    datasets/\n",
        "    ├── real_capture/\n",
        "    │   └── list_file/\n",
        "    │       ├── val_list.txt\n",
        "    │   └── Raw/\n",
        "    │       ├── Xiaomi_0001.dng\n",
        "    │       ├── ...\n",
        "    │   └── ref_sRGB/\n",
        "    │       ├── Xiaomi_0001.jpg\n",
        "    │       ├── ...\n",
        "    ```\n",
        "*   Put pretrained model in /content/DualDn/pretrained_model/, following:\n",
        "\n",
        "  ./pretrained_model/DualDn_Big.pth"
      ],
      "metadata": {
        "id": "_N9_W9r0goea"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Specify the image to be processed\n",
        "\n",
        "\n",
        "*   Modify the val_list.txt to specify which file needed to be denoised.\n",
        "*   Click the 'Save' button.\n"
      ],
      "metadata": {
        "id": "qestxXZBlEhe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q ipywidgets\n",
        "\n",
        "import os\n",
        "from IPython.display import display, clear_output\n",
        "import ipywidgets as widgets\n",
        "\n",
        "# Path to be selected\n",
        "warning = widgets.HTML(\n",
        "    value=\"<span style='color:red; font-size:14px; font-weight:bold;'>⚠️ warning: The last line of the TXT file <strong>must</strong> end with a newline character. (By pressing ENTER)</span>  </span>\"\n",
        ")\n",
        "\n",
        "textarea = widgets.Textarea(\n",
        "    value=open('/content/DualDn/datasets/real_capture/list_file/val_list.txt', 'r', encoding='utf-8').read(),\n",
        "    layout=widgets.Layout(\n",
        "        width='100%',\n",
        "        height='300px',\n",
        "        border='2px solid red'\n",
        "    ),\n",
        "    style={'description_width': '80px'}\n",
        ")\n",
        "\n",
        "# Save\n",
        "save_btn = widgets.Button(\n",
        "    description='save',\n",
        "    button_style='success',\n",
        "    tooltip='saving to the list file'\n",
        ")\n",
        "output = widgets.Output()\n",
        "\n",
        "def on_save_clicked(b):\n",
        "    with open('/content/DualDn/datasets/real_capture/list_file/val_list.txt', 'w', encoding='utf-8') as f:\n",
        "        f.write(textarea.value)\n",
        "    with output:\n",
        "        clear_output()\n",
        "        print('✅ Saved to：/content/DualDn/datasets/real_capture/list_file/val_list.txt')\n",
        "\n",
        "save_btn.on_click(on_save_clicked)\n",
        "\n",
        "# Display\n",
        "display(\n",
        "    warning,\n",
        "    textarea,\n",
        "    save_btn,\n",
        "    output\n",
        ")"
      ],
      "metadata": {
        "id": "mioIwg0ringB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Run the inference code.\n",
        "\n",
        "(On an NVIDIA T4 GPU, processing a single 4K image takes approximately 1 minute 30 seconds.)"
      ],
      "metadata": {
        "id": "5AhpVuV3lkN6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python inference_dualdn.py -opt ./options/DualDn_Big.yml --pretrained_model ./pretrained_model/DualDn_Big.pth --val_datasets Real_captured"
      ],
      "metadata": {
        "id": "00HXGQEpcaIb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Check all the results under the folder './results'"
      ],
      "metadata": {
        "id": "0WAXiiSNl6z2"
      }
    }
  ]
}
